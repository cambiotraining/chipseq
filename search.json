[
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "Analysis of ChIP-seq Data",
    "section": "Overview",
    "text": "Overview\nChromatin immunoprecipitation followed by sequencing (ChIP-seq) is a method used to identify binding sites for transcription factors, histone modifications and other DNA-binding proteins across the genome. These materials cover the fundamentals of ChIP-seq data analysis, from raw data processing to downstream applications.\nWe will start with an introduction to ChIP-seq methods, including important considerations when designing your experiments. We will cover the bioinformatic steps in a standard ChIP-seq analysis workflow, covering raw data quality control, trimming/filtering, mapping, duplicate removal, post-mapping quality control, peak calling and peak annotation. We will discuss metrics used for quality assessment of the called peaks when multiple replicates are available, as well as the analysis of differential binding across sample groups. Finally, we will also cover tools and packages that can be used for visualising and exploring your results.\n\n\n\n\n\n\nLearning Objectives\n\n\n\n\nDescribe how ChIP-seq data is generated and what information it provides about the (epi)genome\nRecall the experimental design considerations that are needed when performing ChIP-seq experiments\nUnderstand the bioinformatic steps involved in processing ChIP-seq data\nInterpret and assess the quality of your data and results\nPerform differential binding analysis to compare different groups of samples\n\n\n\n\nTarget Audience\nThis course is aimed at researchers with no prior experience in the analysis of ChIP-seq data, who would like to get started in processing their data using a standardised pipeline and perform downstream analysis and visualisation of their results.\n\n\nPrerequisites\n\nBasic understanding of high-throughput sequencing technologies.\n\nWatch this iBiology video for an excellent overview.\n\nA working knowledge of the UNIX command line (course registration page).\n\nIf you are not able to attend this prerequisite course, please work through our Unix command line materials ahead of the course (up to section 7).\n\nA working knowledge of R (course registration page).\n\nIf you are not able to attend this prerequisite course, please work through our R materials ahead of the course."
  },
  {
    "objectID": "index.html#authors",
    "href": "index.html#authors",
    "title": "Analysis of ChIP-seq Data",
    "section": "Authors",
    "text": "Authors\n\nAbout the authors (alphabetical by surname):\n\nSandra Cortijo  \nAffiliation: Centre National de la Recherche Scientifique: Montpellier\nRoles: writing; conceptualisation; coding\nSergio Martinez Cuesta  \nAffiliation: AstraZeneca, Cambridge\nRoles: writing; conceptualisation; coding\nSankari Nagarajan  Affiliation: University of Manchester\nRoles: writing; conceptualisation\nAshley Sawle  \nAffiliation: Cancer Research UK, Cambridge Institute\nRoles: writing; conceptualisation; coding\n\nDenis Seyres  Affiliation: Universitätsspital Basel: Basel\nRoles: writing; conceptualisation; coding\nHugo Tavares  \nAffiliation: Bioinformatics Training Facility, University of Cambridge\nRoles: writing; conceptualisation; coding"
  },
  {
    "objectID": "index.html#citation",
    "href": "index.html#citation",
    "title": "Analysis of ChIP-seq Data",
    "section": "Citation",
    "text": "Citation\n\nPlease cite these materials if:\n\nYou adapted or used any of them in your own teaching.\nThese materials were useful for your research work. For example, you can cite us in the methods section of your paper: “We carried our analyses based on the recommendations in Cortijo S et al. (2023).”.\n\nYou can cite these materials as:\n\nCortijo S, Martinez Cuesta S, Nagarajan S, Sawle A, Seyres D, Tavares H (2023) “cambiotraining/chipseq: Analysis of ChIP-seq Data”, https://cambiotraining.github.io/chipseq/\n\nOr in BibTeX format:\n@Misc{,\n  author = {Cortijo, Sandra AND Martinez Cuesta, Sergio AND Nagarajan, Sankari AND Sawle, Ashley AND Seyres, Denis AND Tavares, Hugo},\n  title = {cambiotraining/chipseq: Analysis of ChIP-seq Data},\n  month = {July},\n  year = {2023},\n  url = {https://cambiotraining.github.io/chipseq/}\n}"
  },
  {
    "objectID": "index.html#acknowledgements",
    "href": "index.html#acknowledgements",
    "title": "Analysis of ChIP-seq Data",
    "section": "Acknowledgements",
    "text": "Acknowledgements\n\nThere are many online resources that inspired our own materials (e.g. package vignettes) and we cite them where relevant.\nWe also recommend the following training materials:\n\nUnderstanding chromatin biology using high throughput sequencing from the Harvard Chan Bioinformatics Core\nIntroduction to ChIPseq using HPC from the Harvard Chan Bioinformatics Core\nChIP-seq analysis from the Babraham Institute"
  },
  {
    "objectID": "setup.html#data",
    "href": "setup.html#data",
    "title": "2  Data & Setup",
    "section": "Data",
    "text": "Data\nThe data used in these materials is provided as a zip file. Download and unzip the folder to your Desktop to follow along with the materials.\n\n  Download"
  },
  {
    "objectID": "setup.html#setup",
    "href": "setup.html#setup",
    "title": "2  Data & Setup",
    "section": "Setup",
    "text": "Setup\nTo run the analysis covered in this workshop, you will broadly need two things:\n\nR/RStudio for all the downstream analysis (i.e. after peak calling using the nf-core/chipseq workflow). These analyses can typically be run on your local computer and on any OS (macOS, Windows, Linux).\nA Linux environment to run the pre-processing steps and peak calling (i.e. running the nf-core/chipseq workflow). We highly recommend using a dedicated server (typically a HPC) for this step. Technically, you can also run this workflow on Windows via WSL2 (we provide instructions below), but we do not recommend it for production runs.\n\n\nR and RStudio\n\nWindowsmacOSLinux\n\n\nDownload and install all these using default options:\n\nR\nRTools\nRStudio\n\n\n\nDownload and install all these using default options:\n\nR\nRStudio\n\n\n\n\nGo to the R installation folder and look at the instructions for your distribution.\nDownload the RStudio installer for your distribution and install it using your package manager.\n\n\n\n\n\n\nR Packages\nOpen RStudio and run the following:\n# install BiocManager if not installed already\nif (!require(\"BiocManager\", quietly = TRUE)){\n  install.packages(\"BiocManager\")\n}\n\n# Install all packages used\nBiocManager::install(c(\"GenomicRanges\", \"rtracklayer\", \"plyranges\", \"ChIPseeker\", \"profileplyr\", \"ggplot2\", \"DiffBind\"))\n\n\nConda/Mamba\nFor the command-line tools covered in the course you will need a Linux machine (or WSL2, if you are on Windows - see Section 2.2.6).\nIf you are an experienced Linux user, you can install/compile each tool individually using your preferred method. Otherwise, we recommend doing it via the Mamba package manager. If you already use Conda/Mamba you can skip this step.\nTo make a fresh install of Mamba, you can run:\nwget \"https://github.com/conda-forge/miniforge/releases/latest/download/Mambaforge-$(uname)-$(uname -m).sh\"\nbash Mambaforge-$(uname)-$(uname -m).sh\nAnd follow the instructions on the terminal, accepting the defaults. Make sure to restart your terminal after the installation completes.\nThese instructions also work if you’re using a HPC server.\n\n\nNextflow\nWe recommend having a dedicated environment for Nextflow, which you can use across multiple pipelines you use in the future. Assuming you’ve already installed Conda/Mamba, open your terminal and run:\nmamba create --name nextflow nextflow\nWhenever you want to use nextflow, you need to activate your environment with conda activate nextflow.\n\n\nChIP-seq tools\nFor other command-line tools that we covered in the workshop, you can install them in their own conda environment:\nmamba create --name chipseq\nmamba install --name chipseq idr deeptools meme homer\nWhen you want to use any of them, make sure to activate your environment first with conda activate chipseq.\n\n\nWindows WSL2\n\n\n\n\n\n\nWarning\n\n\n\nWe highly recommend running the raw data processing pipeline on a dedicated Linux server (typically a HPC), not directly on Windows via WSL2. Although you can technically run the entire pipeline on WSL2, it may be a very suboptimal way of doing so for real data.\n\n\nThe Windows Subsystem for Linux (WSL2) runs a compiled version of Ubuntu natively on Windows. There are detailed instructions on how to install WSL on the Microsoft documentation page. Briefly:\n\nClick the Windows key and search for Windows PowerShell, open it and run the command: wsl --install.\nRestart your computer.\nClick the Windows key and search for Ubuntu, which should open a new terminal.\nFollow the instructions to create a username and password (you can use the same username and password that you have on Windows, or a different one - it’s your choice).\nYou should now have access to a Ubuntu Linux terminal. This (mostly) behaves like a regular Ubuntu terminal, and you can install apps using the sudo apt install command as usual.\n\n\nSetup directories\nAfter WSL is installed, it is useful to create shortcuts to your files on Windows. Your C:\\ drive is located in /mnt/c/ (equally, other drives will be available based on their letter). For example, your desktop will be located in: /mnt/c/Users/<WINDOWS USERNAME>/Desktop/. It may be convenient to set shortcuts to commonly-used directories, which you can do using symbolic links, for example:\n\nDocuments: ln -s /mnt/c/Users/<WINDOWS USERNAME>/Documents/ ~/Documents\n\nIf you use OneDrive to save your documents, use: ln -s /mnt/c/Users/<WINDOWS USERNAME>/OneDrive/Documents/ ~/Documents\n\nDesktop: ln -s /mnt/c/Users/<WINDOWS USERNAME>/Desktop/ ~/Desktop\nDownloads: ln -s /mnt/c/Users/<WINDOWS USERNAME>/Downloads/ ~/Downloads\n\n\n\nDocker for WSL\nWe’ve experienced issues in the past when running Nextflow pipelines from WSL2 with -profile singularity. As an alternative, you can instead use Docker, which is another software containerisation solution. To set this up, you can follow the instructions given on the Microsoft Documentation: Get started with Docker remote containers on WSL 2.\nOnce you have Docker set and installed, you can then use -profile docker when running your Nextflow command.\n\n\n\nSingularity\nSingularity is a software for running a virtual operating system locally (known as a container) and popularly used for complex bioinformatic pipelines. Nextflow supports the use of Singularity for managing its software and we recommend its use it on HPC servers. Singularity is typically installed by your HPC admins, otherwise request that they do so.\nHowever, if you want to run the analysis locally on your computer (again, we do not recommend you to do so), then you can install Singularity following the instructions below.\n\nWindowsmacOSLinux\n\n\nYou can use Singularity from the Windows Subsystem for Linux (see Section 2.2.6). Once you setup WSL, you can follow the instructions for Linux.\n\n\nSingularity is not available for macOS.\n\n\nThese instructions are for Ubuntu or Debian-based distributions1.\nsudo apt update && sudo apt upgrade && sudo apt install runc\ncodename=$(lsb_release -c | sed 's/Codename:\\t//')\nwget -O singularity.deb https://github.com/sylabs/singularity/releases/download/v3.10.2/singularity-ce_3.11.4-${codename}_amd64.deb\nsudo dpkg -i singularity.deb\nrm singularity.deb"
  },
  {
    "objectID": "materials/01-peak_calling.html#peak-calling-workflow",
    "href": "materials/01-peak_calling.html#peak-calling-workflow",
    "title": "3  Peak Calling",
    "section": "3.1 Peak Calling Workflow",
    "text": "3.1 Peak Calling Workflow\nOne of the main steps in analysing ChIP-seq data is to identify regions of the genome enriched for sequencing reads, usually referred to as peak calling. These peaks are indicative of regions of the genome where our protein of interest binds to the DNA.\nThere are several steps involved before we do the actual peak calling, namely filtering the sequencing reads for quality and aligning them to the reference genome. Because many of these steps are relatively standard, the bioinformatic community has built pipelines that can be used to automate these data processing steps in a scalable manner.\nWe will use the Nextflow pipeline developed by the nf-core project, which we will refer as nf-core/chipseq. These pipelines are very well documented, with many options available to customise our analysis. The main advantage of these workflows is that they chain together dozens of tools, can process an arbitrary number of samples and can be run both locally and on HPC clusters.\nAs part of their output they also provide an interactive quality control report (HTML file), which is very useful to identify any issues with our samples early on."
  },
  {
    "objectID": "materials/01-peak_calling.html#running-nf-corechipseq",
    "href": "materials/01-peak_calling.html#running-nf-corechipseq",
    "title": "3  Peak Calling",
    "section": "3.2 Running nf-core/chipseq",
    "text": "3.2 Running nf-core/chipseq\nA typical command to run this workflow is given here:\nnextflow run nf-core/chipseq \\\n  -profile singularity \\\n  --input samplesheet.csv \\\n  --outdir path/to/results \\\n  --fasta path/to/genome.fasta.gz \\\n  --gff path/to/annotation.gff.gz \\\n  --blacklist path/to/exclusion_lists.bed.gz \\\n  --macs_gsize 2700000000 \\\n  --min_reps_consensus 2\nWhere:\n\n-profile singularity is the mode we want to use for software management. Singularity is recommended when running analysis on HPC clusters. Other alternatives include conda and docker.\n--input is a CSV file containing information about our samples names and the directory paths to their respective FASTQ files. The format of this file is fully detailed in the documentation.\n--outdir is the output directory where we want our results to be saved. This directory will be created if it does not already exist.\n--fasta and --gff are the directory paths to the reference genome and gene annotation, respectively. These can be typically be downloaded from public repositories such as ENSEMBL.\n--blacklist is the directory path to a BED file containing regions of the genome to exclude from the analysis (regions identified as problematic for peak calling).\n--macs_gsize is the estimated mappable genome size to be used as input to the MACS software. The MACS documentation recommends using 2.7e9 for the human genome and 1.87e9 for mouse.\n--min_reps_consensus is the minimum number of replicates where a peak should be observed to be included in a “consensus” peak set.\n\nWhen you start running the pipeline, you will get a progress log printed on the terminal and a message will be printed when it completes.\nBy default the pipeline runs MACS in broad peak mode. If you want to run it in narrow peak mode (e.g. if you’re studying transcription factors or narrow histone marks) you have to add the option --narrow_peak to your command."
  },
  {
    "objectID": "materials/01-peak_calling.html#pipeline-outputs",
    "href": "materials/01-peak_calling.html#pipeline-outputs",
    "title": "3  Peak Calling",
    "section": "3.3 Pipeline outputs",
    "text": "3.3 Pipeline outputs\nThe nf-core/chipseq workflow generates many output files, which are explained in detail in the workflow documentation. We highlight some of the more relevant files we will use throughout our analysis:\n\nMultiQC report: this is the quality control report, which is usually the first thing to look at once we run our pipeline. This is located in multiqc/<PEAK TYPE>/multiqc_report.html.\nCoverage tracks: these files are in “bigwig” format, a compact representation of the genome coverage of each sample and can be used in genome browsers such as IGV (more on this below). You can find these files in bwa/mergedLibrary/bigwig/*.bigWig, with one file per sample. The coverage values in these files are normalised to 1M mapped reads.\nCalled peaks: files containing the peak intervals identified by the MACS software. These files are in standard BED format (more details in the MACS documentation page). These files are located in bwa/mergedLibrary/macs2/<PEAK_TYPE>/*.broadPeak.\nConsensus peaks: these are the BED files containing the consensus peak intervals identified in a minimum number of replicates set by the pipeline option mentioned above. A consensus file is generated per antibody and these can also be loaded into IGV. These files are located in bwa/mergedLibrary/macs2/<PEAK_TYPE>/consensus/<ANTIBODY>/*.bed.\n\nThere are many more output files, which can be useful depending on the analysis you want to do. But these are the main ones we will focus on for now."
  },
  {
    "objectID": "materials/01-peak_calling.html#quality-report",
    "href": "materials/01-peak_calling.html#quality-report",
    "title": "3  Peak Calling",
    "section": "3.4 Quality report",
    "text": "3.4 Quality report\nThe MultiQC report generated by nf-core/chipseq contains a range of visualisations and metrics that can be used to assess the quality of our samples, from the sequencing reads, to the mapping all the way down to the peak calling.\n\n3.4.1 Read quality\nThe first few sections of the report show:\n\nThe results of the FastQC software (both before and after quality filtering), reporting average read quality, adapter contamination, GC content of our reads, amongst others. See the FastQC documentation for full details.\nA summary of the results from running the cutadapt software, which is used for quality-filtering of our reads and trimming adapter contaminations.\n\nNowadays sequences tend to be very high quality, so it is unusual to have serious problems at this stage. However, if a very high fraction of your reads was filtered out, you should revisit what may have happened during library preparation and sequencing.\n\n\n3.4.2 Mapping quality\nIn terms of mapping quality, we want to look out for:\n\nWhat fraction of reads mapped to the genome?\nHow many reads are mapped to the genome after de-duplication? ENCODE’s guidelines suggest having 10-20M reads for narrow peaks and 40-50M reads for broader peaks.\nWhat is the % of duplicated reads?\nWhat was our library complexity (complexity curve)?\n\n\n\n3.4.3 ChIP Enrichment\nThis part of the QC report is more specific for ChIP-seq analysis. There are several quality metrics that can be used to assess the quality of the ChIP enrichment:\n\nStrand-shift correlation and the derived metrics NSC and RSC\nFRiP score\nFingerprint plot\nCorrelation between replicates and PCA - in the pipeline this is done with DESeq2 (but deeptools can do this also)"
  },
  {
    "objectID": "materials/01-peak_calling.html#visualising-peaks-in-igv",
    "href": "materials/01-peak_calling.html#visualising-peaks-in-igv",
    "title": "3  Peak Calling",
    "section": "3.5 Visualising peaks in IGV",
    "text": "3.5 Visualising peaks in IGV\nAfter thoroughly analysing our MultiQC report, it is also advisable to visually inspect the coverage tracks for our samples (including input controls). This can give us a good indication of whether our peaks are sharp or broad (or somewhat in-between), whether they tend to occur over gene bodies, promoters, or spread across the genome.\nAlthough we can obtain this information from our MultiQC report, it is still advisable to perform this visual inspection of the data. For example, you can look at genes/regions where you expect binding to occur for your protein of interest, or where you expect differences due to the treatment/conditions you used (e.g. from previous experiments, literature, qPCR, …).\n\n\n\nScreenshot of the IGV program, showing the coverage (normalised per 1M reads) for 3 replicate samples. In this region the peaks seem consistent across replicates, although the bottom one seems to have overal lower coverage. This is something we could investigate further."
  },
  {
    "objectID": "materials/01-peak_calling.html#exercises",
    "href": "materials/01-peak_calling.html#exercises",
    "title": "3  Peak Calling",
    "section": "3.6 Exercises",
    "text": "3.6 Exercises\n\n\n\n\n\n\nRunning nf-core/chipseq\n\n\n\nIn the course data, you will find a shell script named scripts/01-chipseq_workflow.sh. This contains some code to run the Nextflow pipeline on our samples. However, there’s a few things that need fixing first:\n\nFix the samplesheet.csv file where the word “FIXME” appears. You can open this file in a spreadsheet program to fix the issue.\nOpen the script scripts/01-chipseq_workflow.sh using a text editor (you can use nano from the command line, or double-click the file to open it with a graphical text editor). Fix the code where the word “FIXME” appears. Output the results to a directory called results/nf-chipseq.\nRun the script to execute the workflow. Hint: to run a shell script you use the program bash name_of_script.sh\n\nCheck that the workflow starts running successfully. You should get some progress of the different steps printed on the terminal.\nThe workflow will take some time to run (~15 minutes). You don’t need to wait for it to finish before moving on to the next exercise.\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nTo fix the samplesheet we needed to add the correct input sample name to E2-treated samples, which in this case was called “mcf7_input_e2”.\nThe fixed code in the script is:\nnextflow run nf-core/chipseq -profile singularity \\\n  --max_memory 23.GB --max_cpus 8 \\\n  --input samplesheet.csv \\\n  --outdir results/nf-chip \\\n  --fasta $(pwd)/resources/GRCh38.109.chr21.fasta.gz \\\n  --gtf $(pwd)/resources/GRCh38.109.chr21.gtf.gz \\\n  --blacklist $(pwd)/resources/ENCFF356LFX_exclusion_lists.chr21.bed.gz \\\n  --macs_gsize 40000000 \\\n  --min_reps_consensus 2\nAfter saving the fixed script, we ran with with:\nbash scripts/01-chip_workflow.sh\nThe script started running successfully, with the progress being printed on the screen.\n\n\n\n\n\n\n\n\n\n\n\nMultiQC report\n\n\n\nIn the previous exercise we’ve only processed a small number of samples, with fewer reads and one chromosome, due to time constraints. However, the full data includes 14 samples:\n\n6 samples pulled down with BRD4 antibody: 3 control (vehicle, ‘veh’) and 3 estrogen-treated (‘e2’);\n6 samples pulled down with H2Bub1 antibody: 3 control (vehicle, ‘veh’) and 3 estrogen-treated (‘e2’);\n2 input controls for ‘veh’ and ‘e2’ conditions.\n\nWe’ve processed the full dataset through the exact same nf-core/chipseq workflow and the output is in the preprocessed/nf-chip folder.\nUse the file browser to open the MultiQC report generated by the pipeline, which you can find in preprocessed/nf-chipseq/multiqc/broadPeak/multiqc_report.html. Answer the following questions:\n\nWas the quality of the raw FASTQ files acceptable? Was there any evidence for Illumina adapter contamination? Was this solved after trimming? (section “LIB: FastQC (raw)”)\nWhat was the percentage of mapped reads? (section “MERGED LIB: SAMTools (unfiltered)”)\nWere there any samples with >20% duplicate reads? (section “MERGED LIB: Picard (unfiltered)”)\nLooking at the fingerprint plot, what can you tell about the differences between the two antibodies? Do you expect different types of peaks? (section “MERGED LIB: deepTools”)\nFrom the read distribution profiles, do these two proteins bind to similar regions of annotated genes? (section “MERGED LIB: deepTools”)\nWas the peak count similar between the two antibodies? How about between replicates and treatments? (section “MERGED LIB: MACS2 peak count”)\nThe ENCODE project uses the criteria below to evaluate if samples are good quality. Do our samples pass these thresholds? (section “MERGED LIB: MACS2 FRiP score” onwards)\n\n\nFRiP > 1%\nNSC > 1.05\nRSC > 0.8\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nYes, the quality was very high, as is often the case with current Illumina chemistry.\nGenerally the % of mapped reads was above 90%. The mapping rates seemed to be slightly lower for H2Bub1, but it doesn’t seem to be a reason for concern.\nNo, the lowest sample had 87% unique reads (“h2bub1_veh_rep3”), suggesting no reason for concern.\nThe fingerprint plot suggests that H2Bub1 has more consistently localised peaks compared to BRD4, as it shows “sharper” fingerprint curves.\nNo, it seems like BRD4 binds primary upstream of the transcription start site (TSS), whereas H2Bub1 seems to occupy gene bodies (with some bias towards the 5’ of the genes).\nNo, H2Bub1 had substantially more peaks than BRD4. This histone modification marks transcribed genes, so perhaps it is no surprise that so many peaks are found for it.\n\nNone of our samples have FRiP > 1, but this is perhaps to be expected as these do not seem to occur as narrow, sharp peaks, but rather more broad. The same applies for the other criteria, as they are generally more suited to use with sharp peaks.\n\n\n\n\n\n\n\n\n\n\n\n\nVisualising results in IGV\n\n\n\nTo visually inspect your results:\n\nOpen IGV (from the toolbar on the left)\nChoose the “Human (hg38)” genome on the top-right drop-down menu\nGo to “File” -> “Load from file…” and then navigate to preprocessed/nf-chipseq/bwa/mergedLibrary/bigwig/*.bigWig\nChoose all the “bigWig” files in this folder (you can use the Shift key to select multiple files) and click “Open”\nOn the search bar at the top search for “ACTB” to look for enrichment in this region.\n\nIGV is reasonably user-friendly and has many options to customise the display. By right-clicking on the track names on the left you can see many options."
  },
  {
    "objectID": "materials/02-peak_ranges.html#peak-ranges",
    "href": "materials/02-peak_ranges.html#peak-ranges",
    "title": "\n4  Exploring peak ranges\n",
    "section": "\n4.1 Peak ranges",
    "text": "4.1 Peak ranges\nAlthough the nf-core/chipseq workflow generates a peak consensus BED file, it is useful to know how to read and manipulate peak files ourselves. For example, we may want to change our criteria for defining a consensus peak (e.g. require an overlap across more replicates), annotate our peaks, or filter them based on different criteria.\nIn this section, we will see how we can achieve this using dedicated R/Bioconductor packages, designed to work with genomic interval data. The main object used to represent genome intervals in R is called GRanges, which is part of the Bioconductor GenomicRanges package.\nThis object requires at least three pieces of information:\n\nchromosome names (seqnames);\ninterval start and end positions (ranges);\nand strand orientation, either + forward or - reverse (strand).\n\nIn addition, further columns can store additional information, such GC content in the interval, gene annotations overlapping that interval, etc. Here is an example of a simple GRanges object:\n\n\nGRanges object with 10 ranges and 2 metadata columns:\n    seqnames    ranges strand |     score        GC\n       <Rle> <IRanges>  <Rle> | <integer> <numeric>\n  a     chr1   101-111      - |         1  1.000000\n  b     chr2   102-112      + |         2  0.888889\n  c     chr2   103-113      + |         3  0.777778\n  d     chr2   104-114      * |         4  0.666667\n  e     chr1   105-115      * |         5  0.555556\n  f     chr1   106-116      + |         6  0.444444\n  g     chr3   107-117      + |         7  0.333333\n  h     chr3   108-118      + |         8  0.222222\n  i     chr3   109-119      - |         9  0.111111\n  j     chr3   110-120      - |        10  0.000000\n  -------\n  seqinfo: 3 sequences from example genome\n\n\nHere is a quick summary of functions used to access information from GRanges objects (the example code assumes the object is called gr):\n\n# total number of intervals\nlength(gr)\n\n[1] 10\n\n# sequence names (usually chromosomes)\n# with number of intervals for each \nseqnames(gr)\n\nfactor-Rle of length 10 with 4 runs\n  Lengths:    1    3    2    4\n  Values : chr1 chr2 chr1 chr3\nLevels(3): chr1 chr2 chr3\n\n# sequence names only\nseqlevels(gr)\n\n[1] \"chr1\" \"chr2\" \"chr3\"\n\n# sequence (chromosome) lengths\nseqlengths(gr)\n\n   chr1    chr2    chr3 \n1000000  200000   10000 \n\n\nThis type of object is ideal to represent ChIP peak calls, such as those identified by the MACS software. In the following sections we will show a concrete example of this in action."
  },
  {
    "objectID": "materials/02-peak_ranges.html#import-peak-files",
    "href": "materials/02-peak_ranges.html#import-peak-files",
    "title": "\n4  Exploring peak ranges\n",
    "section": "\n4.2 Import peak files",
    "text": "4.2 Import peak files\nTo start our analysis, we start by loading the packages we will use:\n\n# Packages ----\n\n# load packages\nlibrary(rtracklayer) # for importing BED/GFF/etc.\nlibrary(plyranges)   # for working with GenomicRanges\nlibrary(ChIPseeker)  # to annotate peaks\nlibrary(profileplyr) # for profile heatmaps\nlibrary(ggplot2)\n\n# change the default ggplot theme\ntheme_set(theme_classic(base_size = 14))\n\nThe next step is to read information about our chromosome lengths, which is useful to make sure our GRanges object uses the correct information for our organism. We generated this information from our reference genome FASTA file and stored it as a tab-delimited file, which we read using standard R functions:\n\n# Chromosome info ----\n\n# read chromosome sizes (for GRanges annotation)\nchroms <- read.table(\"resources/GRCh38.109.chrom_sizes.tsv\", \n                     col.names = c(\"seqnames\", \"seqlengths\"))\n\n# order chromosomes in a more intuititve manner\n# and retain only autosomes (no contigs, no MT)\nchroms <- chroms[match(c(1:22, \"X\", \"Y\"), chroms$seqnames), ]\n\n# if you had MT, you can use this code to set it as circular\nchroms$is_circular <- chroms$seqnames == \"MT\"\n\n# view table\nchroms\n\n   seqnames seqlengths is_circular\n1         1  248956422       FALSE\n12        2  242193529       FALSE\n16        3  198295559       FALSE\n17        4  190214555       FALSE\n18        5  181538259       FALSE\n19        6  170805979       FALSE\n20        7  159345973       FALSE\n21        8  145138636       FALSE\n22        9  138394717       FALSE\n2        10  133797422       FALSE\n3        11  135086622       FALSE\n4        12  133275309       FALSE\n5        13  114364328       FALSE\n6        14  107043718       FALSE\n7        15  101991189       FALSE\n8        16   90338345       FALSE\n9        17   83257441       FALSE\n10       18   80373285       FALSE\n11       19   58617616       FALSE\n13       20   64444167       FALSE\n14       21   46709983       FALSE\n15       22   50818468       FALSE\n24        X  156040895       FALSE\n25        Y   57227415       FALSE\n\n\nBecause we have several peak files generated by MACS (one per sample and antibody), we will use some programmatic tricks to import them automatically, rather than having to repeat our code dozens of times.\nFirst, we find all the files that start with the word brd4_, followed by any characters (that’s what the .* means - it’s a regular expression), followed by broadPeak (to match the file extension of our MACS files).\n\n# Import peaks ----\n\n# list peak files\nbrd4_files <- list.files(path = \"preprocessed/nf-chipseq\", \n                         pattern = \"brd4_.*broadPeak\", \n                         recursive = TRUE,\n                         full.names = TRUE)\nnames(brd4_files) <- gsub(\"_peaks.broadPeak\", \"\", \n                          basename(brd4_files))\n\nbrd4_files\n\n                                                                             brd4_e2_rep1 \n \"preprocessed/nf-chipseq/bwa/mergedLibrary/macs2/broadPeak/brd4_e2_rep1_peaks.broadPeak\" \n                                                                             brd4_e2_rep2 \n \"preprocessed/nf-chipseq/bwa/mergedLibrary/macs2/broadPeak/brd4_e2_rep2_peaks.broadPeak\" \n                                                                             brd4_e2_rep3 \n \"preprocessed/nf-chipseq/bwa/mergedLibrary/macs2/broadPeak/brd4_e2_rep3_peaks.broadPeak\" \n                                                                            brd4_veh_rep1 \n\"preprocessed/nf-chipseq/bwa/mergedLibrary/macs2/broadPeak/brd4_veh_rep1_peaks.broadPeak\" \n                                                                            brd4_veh_rep2 \n\"preprocessed/nf-chipseq/bwa/mergedLibrary/macs2/broadPeak/brd4_veh_rep2_peaks.broadPeak\" \n                                                                            brd4_veh_rep3 \n\"preprocessed/nf-chipseq/bwa/mergedLibrary/macs2/broadPeak/brd4_veh_rep3_peaks.broadPeak\" \n\n\nWe then apply the function import() to this list of files (using lapply()), which automatically generates GRanges objects from the BED files. We also make sure to bind them all together into a single GRanges object.\n\n# take the peak files, and then...\nbrd4_ranges <- brd4_files |> \n  # ... loop through and import them, and then...\n  lapply(import, \n         format = \"broadPeak\") |> \n  # ... bind them all together\n  bind_ranges(.id = \"sample\")\n\nbrd4_ranges\n\nGRanges object with 76318 ranges and 6 metadata columns:\n          seqnames              ranges strand |                   name\n             <Rle>           <IRanges>  <Rle> |            <character>\n      [1]        1       778916-779334      * |    brd4_e2_rep1_peak_1\n      [2]        1       923724-925774      * |    brd4_e2_rep1_peak_2\n      [3]        1       940347-941420      * |    brd4_e2_rep1_peak_3\n      [4]        1       958835-959478      * |    brd4_e2_rep1_peak_4\n      [5]        1       966575-967254      * |    brd4_e2_rep1_peak_5\n      ...      ...                 ...    ... .                    ...\n  [76314]        X 154019432-154019886      * | brd4_veh_rep3_peak_2..\n  [76315]        X 154397616-154398734      * | brd4_veh_rep3_peak_2..\n  [76316]        X 154411351-154412020      * | brd4_veh_rep3_peak_2..\n  [76317]        X 154428300-154428959      * | brd4_veh_rep3_peak_2..\n  [76318]        X 154478146-154478744      * | brd4_veh_rep3_peak_2..\n              score signalValue    pValue    qValue        sample\n          <numeric>   <numeric> <numeric> <numeric>         <Rle>\n      [1]        12     3.27391   3.64994   1.20458  brd4_e2_rep1\n      [2]        27     4.32637   5.48032   2.74516  brd4_e2_rep1\n      [3]        21     3.98874   4.85482   2.18338  brd4_e2_rep1\n      [4]        18     3.75835   4.45139   1.84186  brd4_e2_rep1\n      [5]        24     4.13079   5.13008   2.44575  brd4_e2_rep1\n      ...       ...         ...       ...       ...           ...\n  [76314]        17     4.20761   5.26363   1.73490 brd4_veh_rep3\n  [76315]        26     4.67337   6.33105   2.65508 brd4_veh_rep3\n  [76316]        28     4.90174   6.59650   2.85383 brd4_veh_rep3\n  [76317]        18     4.27710   5.40107   1.85129 brd4_veh_rep3\n  [76318]        16     4.13966   5.13316   1.62427 brd4_veh_rep3\n  -------\n  seqinfo: 54 sequences from an unspecified genome; no seqlengths\n\n\nFinally, we do some tidying up, by keeping only chromosomes of interest (we get rid of contigs and the mitochondrial genome, for example) and adding genome information to our GRanges.\n\n# subset ranges to contain only main chromosomes\nbrd4_ranges <- brd4_ranges[seqnames(brd4_ranges) %in% chroms$seqnames, ]\nseqlevels(brd4_ranges) <- chroms$seqnames\nbrd4_ranges <- set_genome_info(brd4_ranges, \n                               genome = \"GRCh38\",\n                               seqnames = chroms$seqnames,\n                               seqlengths = chroms$seqlengths,\n                               is_circular = chroms$is_circular)\n\nYou may have noticed earlier, when we loaded our packages, that we’re using a package called plyranges. This package implements some functions from the popular data manipulation package dplyr, but for GRanges (docs). For example, here we use the function mutate() to add a new column, indicating which treatment our samples belong to:\n\n# add treatment variable\nbrd4_ranges <- brd4_ranges |> \n  mutate(treatment = ifelse(grepl(\"_e2_\", sample), \"e2\", \"veh\"))"
  },
  {
    "objectID": "materials/02-peak_ranges.html#peak-occupancy",
    "href": "materials/02-peak_ranges.html#peak-occupancy",
    "title": "\n4  Exploring peak ranges\n",
    "section": "\n4.3 Peak occupancy",
    "text": "4.3 Peak occupancy\nNow that we have our GRanges object, we can calculate the coverage across intervals of our genome, i.e. how many intervals in our genome are covered 1, 2, 3, 4, etc. times. In our case, this is equivalent to asking how many samples have overlapping peaks in a given interval.\nWe do this using the compute_coverage() function (notice how we also use the filter() function, analogous to the dplyr::filter() function to subset rows of our GRanges based on a condition):\n\n# Coverage ranges ----\n\n# calculate coverage across genome\nbrd4_coverage <- brd4_ranges |> \n  compute_coverage()\n\n# visualise occupancy rates\nbrd4_coverage |> \n  # remove intervals with no coverage at all\n  filter(score > 0) |> \n  # convert to data.frame\n  as.data.frame() |> \n  # barplot of counts for each coverage score\n  ggplot(aes(x = score)) + \n  geom_bar() +\n  scale_x_continuous(breaks = 1:6) +\n  labs(x = \"# overlaps\")\n\n\n\n\nWe can see from our barplot that the frequency drops substantially from 1 to 2 overlaps, by more than half. This may indicate some quality issues with our samples, for example due to unequal FRiP scores (fraction of reads mapped to called peaks), which we’ve seen was an issue from our nf-core/chipseq MultiQC report.\nWe can now generate a set of consensus peaks by doing the following:\n\nidentify intervals that have a coverage of at least 2;\nfilter our original intervals based on the coverage > 2 intervals;\noptionally, we also merge intervals within 1kb of each other (you can adjust this, based on your knowledge of the biology).\n\n\n# get intervals with coverage >= 2\nbrd4_coverage2 <- brd4_coverage |> \n  filter(score >= 2)\n\n# create consensus peak intervals\nbrd4_consensus <- brd4_ranges |> \n  # filter to retain ranges with enough coverage\n  filter_by_overlaps(brd4_coverage2) |> \n  # merge ranges within 1kb of each other\n  reduce(min.gapwidth = 1e3)\n\nUsing this method, we have 11481 intervals.\nAt this stage, we could export these intervals as a BED file, to use in other downstream analysis, or to load into IGV:\n\nwrite_bed(brd4_consensus, \"results/brd4_consensus_overlap2.bed\")"
  },
  {
    "objectID": "materials/02-peak_ranges.html#annotate-peaks",
    "href": "materials/02-peak_ranges.html#annotate-peaks",
    "title": "\n4  Exploring peak ranges\n",
    "section": "\n4.4 Annotate peaks",
    "text": "4.4 Annotate peaks\nAnother useful task we can do is to annotate our peaks based on known gene annotations. We’ve already seen how this is done by the nf-core/chipseq workflow (which uses the HOMER software behind the scenes), but we’ll demonstrate how you can also annotate GRanges objects from within R.\nThe first thing we do is import the GTF file as a TxDb object (this is another standard Bioconductor object used to store gene annotations in a database-like object). We then use the annotatePeak() function (part of the ChIPseeker package), which adds columns to our GRanges object with the annotation outcome.\n\n# Annotate peaks ----\n\n# import GTF as a TxDb object\ngenes <- GenomicFeatures::makeTxDbFromGFF(\"resources/GRCh38.109.gtf.gz\")\n\n# we use ChIPseeker to annotate the peaks\nbrd4_consensus <- brd4_consensus |> \n  annotatePeak(tssRegion = c(-3e3, 3e3),\n               TxDb = genes) |> \n  # convert back to GRanges\n  as.GRanges()\n\n>> preparing features information...         2023-07-19 09:15:40 \n>> identifying nearest features...       2023-07-19 09:15:41 \n>> calculating distance from peak to TSS...  2023-07-19 09:15:41 \n>> assigning genomic annotation...       2023-07-19 09:15:41 \n>> assigning chromosome lengths          2023-07-19 09:15:59 \n>> done...                   2023-07-19 09:15:59 \n\nbrd4_consensus\n\nGRanges object with 11481 ranges and 9 metadata columns:\n          seqnames              ranges strand |       annotation   geneChr\n             <Rle>           <IRanges>  <Rle> |      <character> <integer>\n      [1]        1       778688-779334      * | Promoter (<=1kb)         1\n      [2]        1       923557-926380      * | Promoter (<=1kb)         1\n      [3]        1       939974-943307      * | Promoter (<=1kb)         1\n      [4]        1       958835-959478      * | Promoter (<=1kb)         1\n      [5]        1       966550-967254      * | Promoter (<=1kb)         1\n      ...      ...                 ...    ... .              ...       ...\n  [11477]        X 154762455-154764031      * | Promoter (<=1kb)        23\n  [11478]        X 155026794-155027456      * | Promoter (<=1kb)        23\n  [11479]        X 155070742-155071909      * | Promoter (<=1kb)        23\n  [11480]        X 155216022-155216875      * | Promoter (<=1kb)        23\n  [11481]        X 155612452-155613133      * | Promoter (<=1kb)        23\n          geneStart   geneEnd geneLength geneStrand          geneId\n          <integer> <integer>  <integer>  <integer>     <character>\n      [1]    778747    805994      27248          1 ENSG00000237491\n      [2]    923923    944574      20652          1 ENSG00000187634\n      [3]    940346    942173       1828          1 ENSG00000187634\n      [4]    944203    959256      15054          2 ENSG00000188976\n      [5]    966502    975008       8507          1 ENSG00000187583\n      ...       ...       ...        ...        ...             ...\n  [11477] 154762742 154777688      14947          1 ENSG00000130826\n  [11478] 155026844 155060304      33461          1 ENSG00000165775\n  [11479] 155061622 155071136       9515          2 ENSG00000182712\n  [11480] 155216460 155239841      23382          1 ENSG00000155959\n  [11481] 155612572 155738214     125643          1 ENSG00000168939\n             transcriptId distanceToTSS\n              <character>     <numeric>\n      [1] ENST00000655765             0\n      [2] ENST00000616016             0\n      [3] ENST00000478729             0\n      [4] ENST00000327044             0\n      [5] ENST00000379409            48\n      ...             ...           ...\n  [11477] ENST00000620277             0\n  [11478] ENST00000369498             0\n  [11479] ENST00000369484             0\n  [11480] ENST00000286428             0\n  [11481] ENST00000676089             0\n  -------\n  seqinfo: 24 sequences from an unspecified genome; no seqlengths\n\n\nThis new annotate object can be used, for example, to visualise how many peaks have each annotation:\n\n# barplot of annotations\nbrd4_consensus |> \n  # remove gene IDs from exon/intro annotations for cleaner plot\n  mutate(annotation = gsub(\"Exon .*\", \"Exon\", annotation)) |> \n  mutate(annotation = gsub(\"Intron .*\", \"Intron\", annotation)) |> \n  # make plot\n  as.data.frame() |> \n  ggplot(aes(annotation)) +\n  geom_bar() +\n  coord_flip()\n\n\n\n\nWe can see that most peaks are within 1kb of the promoter region of the annotated transcripts. We might expect this to be the case, as we’d seen earlier from the read distribution profiles (on the MultiQC report from nf-core/chipseq) that BRD4 seems to occur upstream of the TSS."
  },
  {
    "objectID": "materials/02-peak_ranges.html#exercise-h2bub1-peaks",
    "href": "materials/02-peak_ranges.html#exercise-h2bub1-peaks",
    "title": "\n4  Exploring peak ranges\n",
    "section": "\n4.5 Exercise: H2Bub1 peaks",
    "text": "4.5 Exercise: H2Bub1 peaks\n\n\n\n\n\n\nExercise\n\n\n\n\n\n\nWe now want to do a similar analysis for the H2Bub1 histone ChIP. In summary, we want to:\n\nImport all the H2Bub1 broadPeak files generated by MACS into a GRanges object.\nCalculate interval coverage and visualise it as a barplot.\nCreate a GRanges object of consensus peaks called in at least 2 samples.\nMake a barplot of annotations.\n\nWhile you do this analysis, what can you conclude about the differences between H2Bub1 and BRD4 in terms of their ChIP profiles?\nWe already provide a code skeleton for you to do this, with some “FIXME” for you to correct.\n\nCode skeleton\nNote, this code is provided in the accompanying course materials script. It’s only shown here for reference.\n\n# !!!FIX!!! list peak files \nh2bub1_files <- list.files(path = \"preprocessed/nf-chipseq\",\n                           pattern = \"FIXME\",\n                           recursive = TRUE,\n                           full.names = TRUE)\nnames(h2bub1_files) <- gsub(\"_peaks.broadPeak\", \"\",\n                            basename(h2bub1_files))\n\n# take the peak files, and then...\nh2bub1_ranges <- h2bub1_files |>\n  # ... loop through and import them, and then...\n  lapply(import,\n         format = \"broadPeak\") |>\n  # ... bind them all together\n  bind_ranges(.id = \"sample\")\n\n# subset ranges to contain only main chromosomes\nh2bub1_ranges <- h2bub1_ranges[seqnames(h2bub1_ranges) %in% chroms$seqnames, ]\nseqlevels(h2bub1_ranges) <- chroms$seqnames\nh2bub1_ranges <- set_genome_info(h2bub1_ranges,\n                                 genome = \"GRCh38\",\n                                 seqnames = chroms$seqnames,\n                                 seqlengths = chroms$seqlengths,\n                                 is_circular = chroms$is_circular)\n\n# add treatment variable\nh2bub1_ranges <- h2bub1_ranges |>\n  mutate(treatment = ifelse(grepl(\"_e2_\", sample), \"e2\", \"veh\"))\n\n# !!!FIX!!! calculate coverage across genome\nh2bub1_coverage <- FIXME\n\n# occupancy rates\nh2bub1_coverage |>\n  # remove intervals with no coverage at all\n  filter(score > 0) |>\n  # convert to data.frame\n  as.data.frame() |>\n  # barplot of counts for each coverage score\n  ggplot(aes(x = score)) +\n  geom_bar() +\n  scale_x_continuous(breaks = 1:6) +\n  labs(x = \"# overlaps\")\n\n# !!!FIX!!! get intervals with coverage >= 2\nh2bub1_coverage2 <- FIXME\n\n# !!!FIX!!! create consensus peak intervals\nh2bub1_consensus <- h2bub1_ranges |>\n  # filter to retain ranges with enough coverage\n  FIXME |>\n  # merge ranges within 1kb of each other\n  reduce(min.gapwidth = 1e3)\n\n# !!!FIX!!! use ChIPseeker to annotate the peaks\nh2bub1_consensus <- FIXME\n\n# barplot of annotations\nh2bub1_consensus |>\n  # remove gene IDs from exon/intro annotations for cleaner plot\n  mutate(annotation = gsub(\"Exon .*\", \"Exon\", annotation)) |>\n  mutate(annotation = gsub(\"Intron .*\", \"Intron\", annotation)) |>\n  # make plot\n  as.data.frame() |>\n  ggplot(aes(annotation)) +\n  geom_bar() +\n  coord_flip()\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe complete analysis code is shown here:\n\n# list peak files\nh2bub1_files <- list.files(path = \"preprocessed/nf-chipseq\", \n                           pattern = \"h2bub1_.*.broadPeak\", \n                           recursive = TRUE,\n                           full.names = TRUE)\nnames(h2bub1_files) <- gsub(\"_peaks.broadPeak\", \"\", \n                            basename(h2bub1_files))\n\n# take the peak files, and then...\nh2bub1_ranges <- h2bub1_files |> \n  # ... loop through and import them, and then...\n  lapply(import, \n         format = \"broadPeak\") |> \n  # ... bind them all together\n  bind_ranges(.id = \"sample\")\n  \n# subset ranges to contain only main chromosomes\nh2bub1_ranges <- h2bub1_ranges[seqnames(h2bub1_ranges) %in% chroms$seqnames, ]\nseqlevels(h2bub1_ranges) <- chroms$seqnames\nh2bub1_ranges <- set_genome_info(h2bub1_ranges, \n                                 genome = \"GRCh38\",\n                                 seqnames = chroms$seqnames,\n                                 seqlengths = chroms$seqlengths,\n                                 is_circular = chroms$is_circular)\n\n# add treatment variable\nh2bub1_ranges <- h2bub1_ranges |> \n  mutate(treatment = ifelse(grepl(\"_e2_\", sample), \"e2\", \"veh\"))\n  \n# calculate coverage across genome\nh2bub1_coverage <- h2bub1_ranges |> \n  compute_coverage()\n\n# occupancy rates\nh2bub1_coverage |> \n  # remove intervals with no coverage at all\n  filter(score > 0) |> \n  # convert to data.frame\n  as.data.frame() |> \n  # barplot of counts for each coverage score\n  ggplot(aes(x = score)) + \n  geom_bar() +\n  scale_x_continuous(breaks = 1:6) +\n  labs(x = \"# overlaps\")\n\n\n\n# get intervals with coverage >= 2\nh2bub1_coverage2 <- h2bub1_coverage |> \n  filter(score >= 2)\n\n# create consensus peak intervals\nh2bub1_consensus <- h2bub1_ranges |> \n  # filter to retain ranges with enough coverage\n  filter_by_overlaps(h2bub1_coverage2) |> \n  # merge ranges within 1kb of each other\n  reduce(min.gapwidth = 1e3)\n  \n# use ChIPseeker to annotate the peaks\nh2bub1_consensus <- h2bub1_consensus |> \n  annotatePeak(tssRegion = c(-3e3, 3e3),\n               TxDb = genes) |> \n  as.GRanges()\n\n>> preparing features information...         2023-07-19 09:16:28 \n>> identifying nearest features...       2023-07-19 09:16:28 \n>> calculating distance from peak to TSS...  2023-07-19 09:16:29 \n>> assigning genomic annotation...       2023-07-19 09:16:29 \n>> assigning chromosome lengths          2023-07-19 09:16:31 \n>> done...                   2023-07-19 09:16:31 \n\n# barplot of annotations\nh2bub1_consensus |> \n  # remove gene IDs from exon/intro annotations for cleaner plot\n  mutate(annotation = gsub(\"Exon .*\", \"Exon\", annotation)) |> \n  mutate(annotation = gsub(\"Intron .*\", \"Intron\", annotation)) |> \n  # make plot\n  as.data.frame() |> \n  ggplot(aes(annotation)) +\n  geom_bar() +\n  coord_flip()\n\n\n\n\nLooking at these results we can conclude that:\n\nH2Bub1 signals are much more consistent across replicates, with hardly a drop in the frequency of intervals with overlap 2 or even 3.\nA much higher fraction of peaks fall in introns, promoters and exons, which makes sense because we had previously seen that H2Bub1 seems to occupy gene bodies."
  },
  {
    "objectID": "materials/02-peak_ranges.html#cross-reference-datasets",
    "href": "materials/02-peak_ranges.html#cross-reference-datasets",
    "title": "\n4  Exploring peak ranges\n",
    "section": "\n4.6 Cross-reference datasets",
    "text": "4.6 Cross-reference datasets\nOften ChIP-seq experiments might be complemented with RNA-seq experiments, to assess changes in gene expression in comparable conditions to those where the ChIP experiment was performed. If that is the case, we may want to cross-reference our annotated peaks with the results from the RNA-seq analysis.\nWe have obtained a list of differentially expressed genes between control and siBRD4 MCF7 cells from the supplementary data in Nagarajan et al. 2017. This should give an indication of which genes change their expression in a BRD4-dependent manner, which may be relevant for us to further filter and/or interpret our peaks.\nIn the code below we start by reading the CSV file with differentially expressed gene IDs, which we then use to filter our annotated consensus peak list.\n\n# Subset peaks ----\n\n# read DEGs from Nagarajan 2017\ndegs <- read.csv(\"resources/degs_nagarajan2017.csv\")\n\n# subset annotated intervals\nbrd4_consensus_degs <- brd4_consensus |> \n  filter(geneId %in% degs$ensembl_gene_id)\n\nWe are left with 397 intervals.\nWe will continue working with this subset of peaks in the next section, to compare the ChIP profiles between differentially expressed genes and other genes."
  },
  {
    "objectID": "materials/03-profile_heatmaps.html#profile-heatmaps",
    "href": "materials/03-profile_heatmaps.html#profile-heatmaps",
    "title": "\n5  Profile heatmaps\n",
    "section": "\n5.1 Profile heatmaps",
    "text": "5.1 Profile heatmaps\nBefore we visualise our data as heatmaps, we need to generate a matrix of binned counts for every peak and around annotations of interest (usually genes). This is a computationally-intense step, so for “real” analysis be sure to run this on a high-performance workstation or cluster (and be ready to wait for a while).\nThe binned counts matrix can be calculated using the deeptools suite. There are a couple of steps involved:\n\nScale the counts of each sample by the respective input controls. These are usually expressed as a ratio of counts on a log scale: log2(sample/input).\nGenerate a matrix of binned (scaled) counts around known genes.\n\nThe first step is achieved using the bamCompare (part of deeptools). Here is how we would generate these counts for one of our samples:\nbamCompare \\\n  -b1 results/nf-chipseq/bwa/mergedLibrary/brd4_e2_rep1.mLb.clN.sorted.bam \\\n  -b2 results/nf-chipseq/bwa/mergedLibrary/mcf7_input_e2.mLb.clN.sorted.bam \\\n  -o results/deeptools/brd4_e2_rep1.log2.bigwig \\\n  --binSize 20 \\\n  --smoothLength 60 \\\n  -p 8\nHere, we have:\n\n\n-b1 is the BAM file for our sample;\n\n-b2 is the BAM file for our input control;\n\n-o is the output file (in bigwig format);\n\n--binSize is the size of the bin (in bp) that we want to summarise the data by (default is 10). The larger this number, the “coarser” the output will be, but it will also run faster and produce smaller files.\n\n--smoothLength will smooth the signal by taking into account the signal of neighbouring regions. This is useful for visualisation.\n\n-p is the number of processors (CPUs) we want to use to run the analysis in parallel. As mentioned earlier, these are a computationally intensive steps, so using more processors can help speed things up.\n\nThis analysis would have to be done for every single sample, so you may want to use some programmatic tricks to automate things (see tip box below).\n\n\n\n\n\n\nLooping samples through bamCompare\n\n\n\n\n\nOne way to run bamCompare across all our samples in an automated way is to use a “for loop” Below is some code to illustrate this.\nWe take advantage that our files are named consistently to generate our for loop. In the following example we loop through the E2-treated samples (you would have to write another similar loop for the vehicle samples, as they have a different input control).\nfor file in results/nf-chipseq/bwa/mergedLibrary/*_e2_*.bam\ndo \n  # get the prefix from the BAM filename to generate output file\n  prefix=$(basename $file .mLb.clN.sorted.bam)\n\n  # print a message to the screen to keep track of things\n  echo \"bamCompare on ${file}\"\n\n  # run bamCompare\n  bamCompare \\\n    -b1 $file \\\n    -b2 results/nf-chipseq/bwa/mergedLibrary/mcf7_input_e2.mLb.clN.sorted.bam \\\n    -o results/deeptools/${prefix}.log2.bigwig \\\n    --binSize 20 \\\n    --smoothLength 60 \\\n    -p 8\ndone\n\n\n\n\n5.1.1 computeMatrix\n\nThe next step of our analysis is to create a matrix of binned counts for each peak and gene annotation. This is done using the computeMatrix tool from deeptools.\nThere are two “modes” in which this tool can compute these counts: reference-point and scale-regions. The difference between these is well illustrated in the documentation.\n\n\nDifference between the two modes for computeMatrix. Image source: deeptools documentation.\n\n\nWhen to use one or the other depends on the type of protein being assessed. For transcription factors, which typically bind to gene promoters, the reference-point mode probably makes sense, as it will show the signal around the TSS. For proteins with broader signals, or that cover gene bodies (like our H2Bub1), the scale-regions might make more sense instead.\nHere is some the code we used to generate this matrix, using as input the scaled bigwig files from bamCompare:\ncomputeMatrix scale-regions \\\n  --regionsFileName resources/GRCh38.109.gtf.gz \\\n  --scoreFileName results/deeptools/brd4_*.log2.bigwig \\\n  --outFileName results/deeptools/brd4.log2.mat.gz \\\n  --blackListFileName resources/ENCFF356LFX_exclusion_lists.bed.gz \\\n  --upstream 2000 \\\n  --downstream 2000 \\\n  --skipZeros \\\n  --binSize 20 \\\n  -p 8\nWhere:\n\n\n--regionsFileName is the name of the annotations we want to use to estimate the matrix of counts. Typically the GTF of gene annotations is used (but you could use a different annotation, e.g. for a small subset of genes of interest).\n\n--scoreFileName is the name of the files we want to calculate the binned counts on. Notice how we use the * wildcard to match all the BRD4.\n\n--outFileName is the name for the output file, which is automatically compressed using the ‘gzip’ algorithm (thus we save it with extension .gz).\n\n--blackListFileName excludes regions falling in our exclusions list from being processed.\n\n--skipZeros skips regions that have no counts.\n\n--upstream and --downstream is the number of bp upstream and downstream of the TSS that we want to summarise counts, respectively.\n\n--binSize and -p have the same meaning as above for bamCompare.\n\nThis step takes quite a while to run, so we have already generated these files for you (available from preprocessed/deeptools/)."
  },
  {
    "objectID": "materials/03-profile_heatmaps.html#profile-plots",
    "href": "materials/03-profile_heatmaps.html#profile-plots",
    "title": "\n5  Profile heatmaps\n",
    "section": "\n5.2 Profile plots",
    "text": "5.2 Profile plots\nThere are two main types of profile plots that we can do:\n\nDensity plots showing the average signal of our peaks around our regions of interest (often genes).\nA heatmap showing the signal of individual peaks around those same regions.\n\nOnce we have our binned count matrix, generating these is relatively simple using two deeptools commands.\nFor profile density plots we can use:\nplotProfile -m preprocessed/deeptools/brd4.chr21.mat.gz -out results/brd4_profile.png\nAnd for heatmaps we can do:\nplotHeatmap -m preprocessed/deeptools/brd4.chr21.mat.gz -out results/brd4_heatmap.png\nThere are several other options available with both of these tools (look at their documentation: here and here), including the ability to cluster the peaks using K-means clustering. We will leave that as an optional exercise for the reader."
  },
  {
    "objectID": "materials/03-profile_heatmaps.html#profile-heatmaps-in-r",
    "href": "materials/03-profile_heatmaps.html#profile-heatmaps-in-r",
    "title": "\n5  Profile heatmaps\n",
    "section": "\n5.3 Profile heatmaps in R",
    "text": "5.3 Profile heatmaps in R\nAlthough deeptools makes generating these plots relatively simple, we can also produce similar analysis using dedicated R/Bioconductor packages. This has the advantage that it integrates well with our previous analysis in R.\nFirst, we set things up by loading our packages:\n\n# Packages ----\n\n# load packages\nlibrary(rtracklayer) # for importing BED/GFF/etc.\nlibrary(plyranges)   # for working with GenomicRanges\nlibrary(ChIPseeker)  # to annotate peaks\nlibrary(profileplyr) # for profile heatmaps\nlibrary(ggplot2)\n\n# change the default ggplot theme\ntheme_set(theme_classic(base_size = 14))\n\nIf you haven’t run the previous analysis of peaks, you can also read these in from pre-processed files we provide:\n\n# read consensus GRanges\nbrd4_consensus <- readRDS(\"preprocessed/r_objects/brd4_consensus_granges.rds\")\n\nThe matrix of binned counts can be imported into R using the Bioconductor/profileplyr package.\n\n# Profile heatmaps ----\n\n# import the pre-computed matrix from deeptools\nbrd4_prof <- import_deepToolsMat(\"preprocessed/deeptools/brd4.log2.chr21.mat.gz\")\n\nbrd4_prof\n\nclass: profileplyr \ndim: 3138 250 \nmetadata(0):\nassays(6): brd4_e2_rep1.log2 brd4_e2_rep2.log2 ... brd4_veh_rep2.log2\n  brd4_veh_rep3.log2\nrownames: NULL\nrowData names(3): names score dpGroup\ncolnames: NULL\ncolData names(0):\n\n\nThe type of object returned is called a profileplyr object, which is a modified version of a SummarizedExperiment object, often used to store RNA-seq counts. We won’t go into the details of this object here, but you can find detailed information on the package’s vignette.\nThe main things to consider for our purposes are:\n\nThe peak intervals (ranges) over which the data are summarised is available through the rowRanges() slot of the object.\nThe sample information is stored in the sampleData() slot of the object.\nWe can subset the object using [ with the syntax as: object[ranges, bins, samples].\n\nHere are some illustrative examples:\n\n# ranges information\nrowRanges(brd4_prof)\n\nGRanges object with 3138 ranges and 3 metadata columns:\n         seqnames            ranges strand |           names       score\n            <Rle>         <IRanges>  <Rle> |     <character> <character>\n     [1]       21   8238858-8239092      + | ENST00000652328           .\n     [2]       21   8420674-8421003      + | ENST00000652246           .\n     [3]       21 10576291-10576587      + | ENST00000616920           .\n     [4]       21 10028360-10029855      - | ENST00000624662           .\n     [5]       21 13544209-13545185      - | ENST00000431829           .\n     ...      ...               ...    ... .             ...         ...\n  [3134]       21 25934340-25935178      + | ENST00000596669           .\n  [3135]       21 25941601-25952614      + | ENST00000667606           .\n  [3136]       21 25943043-25943145      - | ENST00000516163           .\n  [3137]       21 26158090-26175824      + | ENST00000455275           .\n  [3138]       21 26190706-26190813      + | ENST00000384075           .\n          dpGroup\n         <factor>\n     [1]    genes\n     [2]    genes\n     [3]    genes\n     [4]    genes\n     [5]    genes\n     ...      ...\n  [3134]    genes\n  [3135]    genes\n  [3136]    genes\n  [3137]    genes\n  [3138]    genes\n  -------\n  seqinfo: 1 sequence from an unspecified genome; no seqlengths\n\n# sample information\nsampleData(brd4_prof)\n\nDataFrame with 6 rows and 20 columns\n                    upstream downstream      body  bin.size unscaled.5.prime\n                   <numeric>  <numeric> <numeric> <numeric>        <numeric>\nbrd4_e2_rep1.log2       2000       2000      1000        20                0\nbrd4_e2_rep2.log2       2000       2000      1000        20                0\nbrd4_e2_rep3.log2       2000       2000      1000        20                0\nbrd4_veh_rep1.log2      2000       2000      1000        20                0\nbrd4_veh_rep2.log2      2000       2000      1000        20                0\nbrd4_veh_rep3.log2      2000       2000      1000        20                0\n                   unscaled.3.prime      sample_labels   verbose bin.avg.type\n                          <numeric>        <character> <logical>  <character>\nbrd4_e2_rep1.log2                 0  brd4_e2_rep1.log2     FALSE         mean\nbrd4_e2_rep2.log2                 0  brd4_e2_rep2.log2     FALSE         mean\nbrd4_e2_rep3.log2                 0  brd4_e2_rep3.log2     FALSE         mean\nbrd4_veh_rep1.log2                0 brd4_veh_rep1.log2     FALSE         mean\nbrd4_veh_rep2.log2                0 brd4_veh_rep2.log2     FALSE         mean\nbrd4_veh_rep3.log2                0 brd4_veh_rep3.log2     FALSE         mean\n                   missing.data.as.zero     scale skip.zeros nan.after.end\n                              <logical> <numeric>  <logical>     <logical>\nbrd4_e2_rep1.log2                 FALSE         1       TRUE         FALSE\nbrd4_e2_rep2.log2                 FALSE         1       TRUE         FALSE\nbrd4_e2_rep3.log2                 FALSE         1       TRUE         FALSE\nbrd4_veh_rep1.log2                FALSE         1       TRUE         FALSE\nbrd4_veh_rep2.log2                FALSE         1       TRUE         FALSE\nbrd4_veh_rep3.log2                FALSE         1       TRUE         FALSE\n                   proc.number sort.regions  sort.using ref.point min.threshold\n                     <numeric>  <character> <character>    <list>        <list>\nbrd4_e2_rep1.log2           10         keep        mean                        \nbrd4_e2_rep2.log2           10         keep        mean                        \nbrd4_e2_rep3.log2           10         keep        mean                        \nbrd4_veh_rep1.log2          10         keep        mean                        \nbrd4_veh_rep2.log2          10         keep        mean                        \nbrd4_veh_rep3.log2          10         keep        mean                        \n                   max.threshold generation.method\n                          <list>       <character>\nbrd4_e2_rep1.log2                        deepTools\nbrd4_e2_rep2.log2                        deepTools\nbrd4_e2_rep3.log2                        deepTools\nbrd4_veh_rep1.log2                       deepTools\nbrd4_veh_rep2.log2                       deepTools\nbrd4_veh_rep3.log2                       deepTools\n\n# subset the object for:\n# first 10 peaks\n# first 5 bins\n# first 3 samples\nbrd4_prof[1:10, 1:5, 1:3]\n\nclass: profileplyr \ndim: 10 5 \nmetadata(0):\nassays(3): brd4_e2_rep1.log2 brd4_e2_rep2.log2 brd4_e2_rep3.log2\nrownames: NULL\nrowData names(3): names score dpGroup\ncolnames: NULL\ncolData names(0):\n\n\nOne of the main functions provided in this package is the ability to produce profile heatmaps. These heatmaps can be quite heavy to render graphically, so it’s usually a good idea to subset our ranges.\nIn the following example, we sample a few random intervals to get an idea of occupancy for our BRD4 protein around genes:\n\n# sample 200 peaks randomly\nrandom_peaks <- sample(1:nrow(brd4_prof), 200)\n\n# Plot random peaks to give an idea of occupancy\ngenerateEnrichedHeatmap(brd4_prof[random_peaks, ], \n                        include_group_annotation = FALSE)\n\n\n\n\nWe can see that BRD4 mostly occupies gene promoters. This result does not come as a complete surprise, as we had already seen this in previous analysis.\nFor heatmaps with thousands of peaks, it’s best to save them as PNG, as the plotting device on RStudio can stuggle to render them. Here is an example for all Chr21 peaks we loaded in:\n\n# save as PNG - adjust width, height and resolution to fit your needs\npng(\"results/brd4_heatmap.png\", width = 3000, height = 1500, res = 300)\ngenerateEnrichedHeatmap(brd4_prof, include_group_annotation = FALSE)\ndev.off()\n\nWe can subset our profile object to include only the peaks that overlap with another set of peaks of our interest. For example, we could investigate if the profiles look very different for the set of genes that are differentially expressed in siBRD4 lines.\n\n# read DEGs from Nagarajan 2017\ndegs <- read.csv(\"resources/degs_nagarajan2017.csv\")\n\n# subset annotated intervals \nbrd4_consensus_degs <- brd4_consensus |> \n  filter(geneId %in% degs$ensembl_gene_id)\n\n# subset our profile object to include only the filtered intervals\nbrd4_prof_degs <- brd4_prof |> \n  subsetByOverlaps(brd4_consensus_degs)\n  \n# visualise them\ngenerateEnrichedHeatmap(brd4_prof_degs, include_group_annotation = FALSE)"
  },
  {
    "objectID": "materials/03-profile_heatmaps.html#exercise-heatmap",
    "href": "materials/03-profile_heatmaps.html#exercise-heatmap",
    "title": "\n5  Profile heatmaps\n",
    "section": "\n5.4 Exercise: heatmap",
    "text": "5.4 Exercise: heatmap\n\n\n\n\n\n\nExercise\n\n\n\nBased on the code we showed above, generate a profile heatmap for the H2Bub1 ChIP.\n\nFirst import the matrix of binned counts using import_deepToolsMat() and save it into an object called h2bub1_prof.\nThen generate a heatmap using the generateEnrichedHeatmap() function, making sure you save it as a PNG.\n\nDoes the result match your expectation from previous analysis?\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nHere is the code to import and generate a PNG file with our heatmap:\n\n# import the pre-computed matrix from deeptools\nh2bub1_prof <- import_deepToolsMat(\"preprocessed/deeptools/h2bub1.log2.chr21.mat.gz\")\n\n# save plot as PNG\npng(\"results/h2bub1_heatmap.png\", width = 3000, height = 1500, res = 300)\ngenerateEnrichedHeatmap(h2bub1_prof, include_group_annotation = FALSE)\ndev.off()\n\nIn order to save space, we show a random subset of 200 genes below as an example:\n\n\n\n\n\nThe plot shows that H2Bub1 has broader peaks across whole gene bodies and promoters. This fits with the the peak annotation we did earlier, which showed that most peaks occur in those regions."
  },
  {
    "objectID": "materials/04-diffbind.html#differential-binding",
    "href": "materials/04-diffbind.html#differential-binding",
    "title": "\n6  Differential binding\n",
    "section": "\n6.1 Differential binding",
    "text": "6.1 Differential binding\nWhen multiple conditions are available in our ChIP design (e.g. healthy vs disease, wild-type vs mutant, treated vs control, different cell types, …), we may want to investigate whether certain peaks are differentially bound between them.\nFinding differentially bound regions in the genome is analogous to identifying differentially expressed genes in RNA-seq data. In both cases we are dealing with count data summarised over features (genes/transcripts in the case of RNA-seq and peaks in the case of ChIP-seq). In both cases the biological replicates show larger variability than technical replicates, and the negative binomial model is suitable to compare binding affinities accross samples.\nThere are a number of differential expression packages in R that use the negative binomial model e.g. DESeq2 and edgeR. These methods are wrapped in the DiffBind package that is geared towards analysing differential binding in ChIP-seq data and provides a number of analytical plots as well.\nAs usual, we start by loading our packages:\n\n# Packages ----\n\n# load packages\nlibrary(rtracklayer) # for importing BED/GFF/etc.\nlibrary(plyranges)   # for working with GenomicRanges\nlibrary(ChIPseeker)  # to annotate peaks\nlibrary(profileplyr) # for profile heatmaps\nlibrary(DiffBind)    # for ChIP peak analysis\nlibrary(ggplot2)\n\n# change the default ggplot theme\ntheme_set(theme_classic(base_size = 14))"
  },
  {
    "objectID": "materials/04-diffbind.html#reading-peaks",
    "href": "materials/04-diffbind.html#reading-peaks",
    "title": "\n6  Differential binding\n",
    "section": "\n6.2 Reading peaks",
    "text": "6.2 Reading peaks\nAs is common with Bioconductor packages, the DiffBind package uses its own data structure, called a dba object. To create this, we need to create a CSV file with the following information:\n\nTODO long list of columns\n\nWe’ve already created this for you, so all we need to do is read it in:\n\n# read DiffBind samplesheet\nsamplesheet <- read.csv(\"diffbind_samplesheet.csv\")\n\nhead(samplesheet)\n\n       SampleID                   Tissue Antibody Condition Treatment Replicate\n1  brd4_e2_rep1 MCF7 breast cancer cells     BRD4        NA        e2         1\n2  brd4_e2_rep2 MCF7 breast cancer cells     BRD4        NA        e2         2\n3  brd4_e2_rep3 MCF7 breast cancer cells     BRD4        NA        e2         3\n4 brd4_veh_rep1 MCF7 breast cancer cells     BRD4        NA       veh         1\n5 brd4_veh_rep2 MCF7 breast cancer cells     BRD4        NA       veh         2\n6 brd4_veh_rep3 MCF7 breast cancer cells     BRD4        NA       veh         3\n                                                                    bamReads\n1  preprocessed/nf-chipseq/bwa/mergedLibrary/brd4_e2_rep1.mLb.clN.sorted.bam\n2  preprocessed/nf-chipseq/bwa/mergedLibrary/brd4_e2_rep2.mLb.clN.sorted.bam\n3  preprocessed/nf-chipseq/bwa/mergedLibrary/brd4_e2_rep3.mLb.clN.sorted.bam\n4 preprocessed/nf-chipseq/bwa/mergedLibrary/brd4_veh_rep1.mLb.clN.sorted.bam\n5 preprocessed/nf-chipseq/bwa/mergedLibrary/brd4_veh_rep2.mLb.clN.sorted.bam\n6 preprocessed/nf-chipseq/bwa/mergedLibrary/brd4_veh_rep3.mLb.clN.sorted.bam\n       ControlID\n1  mcf7_input_e2\n2  mcf7_input_e2\n3  mcf7_input_e2\n4 mcf7_input_veh\n5 mcf7_input_veh\n6 mcf7_input_veh\n                                                                   bamControl\n1  preprocessed/nf-chipseq/bwa/mergedLibrary/mcf7_input_e2.mLb.clN.sorted.bam\n2  preprocessed/nf-chipseq/bwa/mergedLibrary/mcf7_input_e2.mLb.clN.sorted.bam\n3  preprocessed/nf-chipseq/bwa/mergedLibrary/mcf7_input_e2.mLb.clN.sorted.bam\n4 preprocessed/nf-chipseq/bwa/mergedLibrary/mcf7_input_veh.mLb.clN.sorted.bam\n5 preprocessed/nf-chipseq/bwa/mergedLibrary/mcf7_input_veh.mLb.clN.sorted.bam\n6 preprocessed/nf-chipseq/bwa/mergedLibrary/mcf7_input_veh.mLb.clN.sorted.bam\n                                                                                    Peaks\n1  preprocessed/nf-chipseq/bwa/mergedLibrary/macs2/broadPeak/brd4_e2_rep1_peaks.broadPeak\n2  preprocessed/nf-chipseq/bwa/mergedLibrary/macs2/broadPeak/brd4_e2_rep2_peaks.broadPeak\n3  preprocessed/nf-chipseq/bwa/mergedLibrary/macs2/broadPeak/brd4_e2_rep3_peaks.broadPeak\n4 preprocessed/nf-chipseq/bwa/mergedLibrary/macs2/broadPeak/brd4_veh_rep1_peaks.broadPeak\n5 preprocessed/nf-chipseq/bwa/mergedLibrary/macs2/broadPeak/brd4_veh_rep2_peaks.broadPeak\n6 preprocessed/nf-chipseq/bwa/mergedLibrary/macs2/broadPeak/brd4_veh_rep3_peaks.broadPeak\n  PeakCaller\n1        bed\n2        bed\n3        bed\n4        bed\n5        bed\n6        bed\n\n\nOnce we have this samplesheet, creating the dba object is relatively simple (note in this case we’re only loading the BRD4 samples):\n\n# create DBA object for BRD4 antibody\nbrd4_dba <- dba(sampleSheet = samplesheet[samplesheet$Antibody == \"BRD4\", ])\n\nbrd4_dba\n\n6 Samples, 12395 sites in matrix (48128 total):\n             ID                   Tissue Treatment Replicate Intervals\n1  brd4_e2_rep1 MCF7 breast cancer cells        e2         1     20240\n2  brd4_e2_rep2 MCF7 breast cancer cells        e2         2     11144\n3  brd4_e2_rep3 MCF7 breast cancer cells        e2         3      2599\n4 brd4_veh_rep1 MCF7 breast cancer cells       veh         1      2922\n5 brd4_veh_rep2 MCF7 breast cancer cells       veh         2     37306\n6 brd4_veh_rep3 MCF7 breast cancer cells       veh         3      2107\n\n\nWithout doing any further analysis, we can already produce a correlation heatmap using the plot() function:\n\n# correlation plot using caller score\nplot(brd4_dba)\n\n\n\n\nThis correlation is calculated based on the score given to each peak, in our case the score that MACS assigns to each called peak. This is not necessarily the best way to look at the correlation between samples, as it doesn’t take into account the actual counts in each peak (that will come later), but it’s a good starting point to look at the correlation between our samples.\nIn our case, we can see that our replicates are not clustering per treatment, suggesting other effects may have played a role in the ChIP profiles.\nThe next step is to count reads in each peak (which is the raw data that will be used to estimate the differential binding). This step takes a long time, so be prepared to wait if you’re running this on your data.\n\n# count reads overlapping peaks \n# this takes a long time to run! So we load pre-computed one\n# brd4_dba <- dba.count(brd4_dba)\nbrd4_dba <- readRDS(\"preprocessed/r_objects/brd4_dba.count.rds\")\n\n# correlation plot based on raw counts\nplot(brd4_dba)\n\n\n\n\nNow, when we call the plot() function the correlation heatmap is instead done from the counts assigned to each peak (rather than peak scores). In this case, we get a clearer clustering of samples by treatment, which is a good sign!\nThe next step in the analysis is to normalise the counts. There are different methods to normalise the counts, and this is discussed at length by the DiffBind authors (see section 7 in the documentation). In summary, these authors argue for caution when applying normalisation methods used for RNA-seq analysis, as those methods assume that most features (peaks in our case, genes in the RNA-seq case) are not differentially expressed/bound between conditions. However, this assumption may not make biological sense in the case of ChIP-seq, as some conditions may dramatically affect the binding profiles genome-wide.\nThis may certainly be the case for BRD4, as we’ve seen from our profile plots that binding is generally higher for E2-treated samples compared to controls. For this reason, the default normalisation method used by DiffBind is a simple library size normalisation, which we apply below.\n\n# normalise counts by library size (default)\nbrd4_dba <- dba.normalize(brd4_dba, normalize = DBA_NORM_LIB)\n\nOne final step before we fit the model that will test for differential binding, is to set the “contrast” of our experiment. This is where we can set which factors should be taken into account when modelling the counts and which comparisons we want to make. There is quite a lot of flexibility in setting these models, which is detailed in the package’s documentation as well as the documentation for DEseq2, which is used behind the scenes.\nIn our case, we only have one factor (treatment) with two conditions (“e2” and “veh”). Therefore, we can set our contrast like so:\n\n# set contrast \nbrd4_dba <- dba.contrast(brd4_dba, \n                         design = ~ Treatment,\n                         reorderMeta = list(Treatment = \"veh\"),\n                         minMembers = 3)\n\nWhere:\n\n\ndesign uses R’s standard model formula syntax to define the variables used to model our counts, in our case “Treatment” (this is one of the columns from our CSV samplesheet).\n\nreorderMeta is used to set the reference level for our Treatment variable; in our case it makes sense to set “veh” as the reference level (control). The default reference level would be whichever comes first alphabetically.\n\nminMembers defines the minimum number of replicates required to run the analysis. The default value is in fact 3, but we’ve set it anyway to be explicit.\n\nFinally, we can fit the statical model using DEseq2’s statistical machinery (the other option is to use DBA_EDGER, which would use that package instead - the results are very comparable).\n\n# run the analysis\nbrd4_dba <- dba.analyze(brd4_dba, \n                        method = DBA_DESEQ2,\n                        bBlacklist = FALSE, \n                        bGreylist = FALSE)\n\nNote that we’ve set two options to FALSE:\n\n\nbBlacklist turns off the behaviour of trying to identify our genome and apply an exclusion list to it. We’ve already done this when we did peak calling with the nf-core/chipseq workflow, so there is no need to do this again.\n\nbGreylist turns off the behaviour of estimating a so-called “greylist”. We talk more about this below.\n\nFinally, with the analysis done, it’s time to extract our results, which are returned as a familiar GRanges object:\n\n# extract diffbound sites\n# keep all peaks, even those that are non-significant\nbrd4_diffbound <- dba.report(brd4_dba, th = 1)\n\nbrd4_diffbound\n\nGRanges object with 12331 ranges and 6 metadata columns:\n          seqnames            ranges strand |      Conc   Conc_e2  Conc_veh\n             <Rle>         <IRanges>  <Rle> | <numeric> <numeric> <numeric>\n   7853         21 42365357-42365757      * |   4.56334   5.53382   0.00000\n   7548         20 53865352-53865752      * |   5.10739   2.25210   6.00409\n   7493         20 53660691-53661091      * |   4.63297   5.54957   1.47889\n   3675         15 74816468-74816868      * |   4.46242   5.40868   0.68917\n   7263         20 44714529-44714929      * |   3.12993   4.12993   0.00000\n    ...        ...               ...    ... .       ...       ...       ...\n  12064 KI270754.1         3352-3752      * |   1.47054   1.44409   1.49652\n   7710         20 63330620-63331020      * |   1.41217   1.40120   1.42307\n   1682         11 31509716-31510116      * |   1.53077   1.53102   1.53053\n   5879         19 16535344-16535744      * |   1.55841   1.55877   1.55805\n  12034 KI270467.1         3240-3640      * |   5.08000   4.95839   5.19215\n                Fold     p-value        FDR\n           <numeric>   <numeric>  <numeric>\n   7853      4.43696 8.71201e-07 0.00756452\n   7548     -3.35432 1.33026e-06 0.00756452\n   7493      3.47205 5.27113e-06 0.01612934\n   3675      3.94028 5.67285e-06 0.01612934\n   7263      4.44204 8.38315e-06 0.01906832\n    ...          ...         ...        ...\n  12064 -0.000219130    0.994758          1\n   7710 -0.000213502    0.994952          1\n   1682  0.000186362    0.995030          1\n   5879  0.000171415    0.995530          1\n  12034 -0.002416403    1.000000          1\n  -------\n  seqinfo: 44 sequences from an unspecified genome; no seqlengths\n\n\nWe can use some plyranges syntax to obtain a summary of how many peaks are differentially bound and in which direction:\n\n# count how many up or down\nbrd4_diffbound |> \n  filter(FDR < 0.05) |> \n  summarise(up = sum(Fold > 0), down = sum(Fold < 0))\n\nDataFrame with 1 row and 2 columns\n         up      down\n  <integer> <integer>\n1        30         4\n\n\nThe result is not particularly striking. It suggests that not many peaks are differentially bound between conditions. Let’s investigate our results a bit further with some visualisations."
  },
  {
    "objectID": "materials/04-diffbind.html#differential-binding-visualisation",
    "href": "materials/04-diffbind.html#differential-binding-visualisation",
    "title": "\n6  Differential binding\n",
    "section": "\n6.3 Differential binding visualisation",
    "text": "6.3 Differential binding visualisation\n\n\n\nThe DiffBind package provides several plotting functions, illustrated below.\nWe start with a PCA, which shows that samples separate by treatment along PC2, but not PC1 (the axis of greatest variance). This suggests that factors other than the treatment influenced our ChIP results. This may explain the relatively low number of differentially bound peaks.\n\n# PCA plot\ndba.plotPCA(brd4_dba, label = DBA_REPLICATE)\n\n\n\n\nAnother common visualisation used in differential analysis is the MA plot. This shows the average normalised read counts on the X-axis and the log-fold change on the Y-axis. This plot can be used to assess the effect of the normalisation on the data (red trend line, which we want to be close to the zero horizontal line) as well as highlighting the significant differentially bound regions (pink points).\n\n# MA plot\ndba.plotMA(brd4_dba)\n\n\n\n\nYou can also generate this plot with ggplot2, if you want to customise it further:\n\n# can also do it with ggplot2\nbrd4_diffbound |> \n  as.data.frame() |> \n  mutate(sig = ifelse(FDR < 0.05, Fold, NA)) |> \n  ggplot(aes(Conc, Fold)) + \n  geom_point(colour = \"grey\") + \n  geom_point(aes(y = sig), colour = \"black\") +\n  geom_hline(yintercept = 0, linetype = \"dashed\")\n\nAnother common visualisation is a volcano plot, which shows the log-fold change on the x-axis and p-values on the y-axis (we don’t show this one, to save space).\n\n# volcano plot\ndba.plotVolcano(brd4_dba)\n\n# can also do it with ggplot2\nbrd4_diffbound |> \n  as.data.frame() |> \n  mutate(sig = ifelse(FDR < 0.05, Fold, NA)) |> \n  ggplot(aes(Fold, -log10(FDR))) + \n  geom_point(colour = \"grey\") + \n  geom_point(aes(x = sig), colour = \"black\") +\n  geom_vline(xintercept = 0, linetype = \"dashed\")\n\nWe can also produce a boxplot of normalised counts, which shows the distribution of counts in the whole dataset, and on the subset of peaks with significant differential binding (both upwards and downwards).\n\n# boxplot of normalised counts\ndba.plotBox(brd4_dba)\n\n\n\n\nIn our case, this boxplot is interesting, as it illustrates that, overall, BRD4 in E2-treated cells seems to have higher binding affinity than in control cells. This might either be biologically reasonable, or it may be an issue with data quality (recall the variation in FRiP scores we’ve seen earlier and the fact that the PCA separates samples from different treatments along PC1). As we are not experts in this biological system, we refrain from making further comments on this.\nFinally, we can visualise the scaled counts in the differentially bound peaks as a heatmap:\n\n# heatmap of DB peaks\ndba.plotHeatmap(brd4_dba, contrast = 1, \n                correlations = FALSE, scale = \"row\")"
  },
  {
    "objectID": "materials/04-diffbind.html#pipeline",
    "href": "materials/04-diffbind.html#pipeline",
    "title": "\n6  Differential binding\n",
    "section": "\n6.4 Pipeline",
    "text": "6.4 Pipeline\n\n\n\nAlthough we’ve broken our analysis down into individual steps, it’s worth nothing that because each function of the DiffBind workflow always returns the dba object with further elements added to it, we can put it all together using |> pipes:\n\n# full pipeline - do not run, it will take too long!\nbrd4_dba <- dba(sampleSheet = samplesheet[samplesheet$Antibody == \"BRD4\", ]) |> \n  dba.count() |> \n  dba.normalize(normalize = DBA_NORM_LIB) |> \n  dba.contrast(reorderMeta = list(Treatment = \"veh\")) |> \n  dba.analyze(method = DBA_DESEQ2,\n              bBlacklist = FALSE, \n              bGreylist = FALSE)\n\n# extract diffbound sites\nbrd4_diffbound <- dba.report(brd4_dba, th = 1)\n\nAs we did before, we can also annotate our differentially bound peaks using ChIPseeker:\n\n# import gene annotation as a transcript database\ngenes <- GenomicFeatures::makeTxDbFromGFF(\"resources/GRCh38.109.gtf.gz\")\n\n# annotate\nbrd4_diffbound <- annotatePeak(brd4_diffbound, \n                               tssRegion = c(-3e3, 3e3),\n                               TxDb = genes) |> \n  as.GRanges()"
  },
  {
    "objectID": "materials/04-diffbind.html#exercises",
    "href": "materials/04-diffbind.html#exercises",
    "title": "\n6  Differential binding\n",
    "section": "\n6.5 Exercises",
    "text": "6.5 Exercises\n\n\n\n\n\n\nExercise\n\n\n\n\n\n\nRun the differential binding analysis for the H2Bub1 ChIP. Because counting reads assigned to each peak takes too long to run, we start by loading a pre-processed file.\nStarting from this object, build a pipeline to run the rest of the steps in the analysis. We already provide a code skeleton for you to do this, with some “FIXME” for you to correct.\n\nCode skeleton\nNote, this code is provided in the accompanying course materials script. It’s only shown here for reference.\n\n# !!!FIX!!! run diffbind analysis\nh2bub1_dba <- readRDS(\"preprocessed/r_objects/h2bub1_dba.count.rds\") |> \n  FIXME\n  \n# !!!FIX!!! extract results as a GRanges object\nbrd4_diffbound <- FIXME \n\n# !!!FIX!!! correlation heatmap for the samples\nFIXME\n\n# !!!FIX!!! PCA plot\nFIXME\n\n# !!!FIX!!! MA plot\nFIXME \n\n# !!!FIX!!! boxplot\nFIXME\n\n# !!!FIX!!! heatmap of differentially bound peaks\nFIXME\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe full pipeline is shown here (but we don’t run all of it, as it would take too long):\n\n# full pipeline\nh2bub1_dba <- dba(sampleSheet = samplesheet[samplesheet$Antibody == \"H2Bub1\", ]) |> \n  dba.count() |> \n  dba.normalize() |> \n  dba.contrast(reorderMeta = list(Treatment = \"veh\")) |> \n  dba.analyze(bBlacklist = FALSE, bGreylist = FALSE)\n\nFor the practical, we start from the pre-processed counts:\n\n# start from pre-processed counts\nh2bub1_dba <- readRDS(\"preprocessed/r_objects/h2bub1_dba.count.rds\") |> \n  dba.normalize() |> \n  dba.contrast(reorderMeta = list(Treatment = \"veh\")) |> \n  dba.analyze(bBlacklist = FALSE, bGreylist = FALSE)\n\n# run the differential binding analysis\nh2bub1_diffbound <- dba.report(h2bub1_dba, th = 1)\n\nWe can then explore our results:\n\n# summarise\nh2bub1_diffbound |> \n  filter(FDR < 0.05) |> \n  summarise(up = sum(Fold > 0), down = sum(Fold < 0))\n\nDataFrame with 1 row and 2 columns\n         up      down\n  <integer> <integer>\n1      3283      1736\n\n# correlation heatmap for the samples\nplot(h2bub1_dba)\n\n\n\n# PCA plot\ndba.plotPCA(h2bub1_dba)\n\n\n\n# MA plot\ndba.plotMA(h2bub1_dba)\n\n\n\n# boxplot\ndba.plotBox(h2bub1_dba)\n\n\n\n# heatmap of differentially bound peaks\ndba.plotHeatmap(h2bub1_dba, contrast = 1, correlations = FALSE, scale = \"row\")\n\n\n\n\nIn this case there are more differentially bound peaks, and the boxplot of normalised counts between conditions is much closer between groups (although still different, which again might make biological sense)."
  }
]